{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import os.path\n",
    "from os.path import normpath, basename\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from PIL import Image\n",
    "from typing import List, Union, Tuple, Any\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''MobilenetV2 in PyTorch.\n",
    "See the paper \"MobileNetV2: Inverted Residuals and Linear Bottlenecks\" for more details.\n",
    "'''\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(inp, oup, kernel_size=3, stride=stride, padding=(1,1,1), bias=False),\n",
    "        nn.BatchNorm3d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm3d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == (1,1,1) and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv3d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm3d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv3d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm3d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv3d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm3d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv3d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm3d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv3d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm3d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000, sample_size=224, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1,  16, 1, (1,1,1)],\n",
    "            [6,  24, 2, (2,2,2)],\n",
    "            [6,  32, 3, (2,2,2)],\n",
    "            [6,  64, 4, (2,2,2)],\n",
    "            [6,  96, 3, (1,1,1)],\n",
    "            [6, 160, 3, (2,2,2)],\n",
    "            [6, 320, 1, (1,1,1)],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        assert sample_size % 16 == 0.\n",
    "        input_channel = int(input_channel * width_mult)\n",
    "        self.last_channel = int(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
    "        self.features = [conv_bn(3, input_channel, (1,2,2))]\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else (1,1,1)\n",
    "                self.features.append(block(input_channel, output_channel, stride, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        self.features.append(conv_1x1x1_bn(input_channel, self.last_channel))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = F.avg_pool3d(x, x.data.size()[-3:])\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.kernel_size[2] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImglistToTensor(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Converts a list of PIL images in the range [0,255] to a torch.FloatTensor\n",
    "    of shape (NUM_IMAGES x CHANNELS x HEIGHT x WIDTH) in the range [0,1].\n",
    "    Can be used as first transform for ``VideoFrameDataset``.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(img_list: List[Image.Image]) -> 'torch.Tensor[NUM_IMAGES, CHANNELS, HEIGHT, WIDTH]':\n",
    "        \"\"\"\n",
    "        Converts each PIL image in a list to\n",
    "        a torch Tensor and stacks them into\n",
    "        a single tensor.\n",
    "\n",
    "        Args:\n",
    "            img_list: list of PIL images.\n",
    "        Returns:\n",
    "            tensor of size ``NUM_IMAGES x CHANNELS x HEIGHT x WIDTH``\n",
    "            \n",
    "        \n",
    "        \"\"\"\n",
    "        # print(type(img_list))\n",
    "        # print(img_list)\n",
    "        # print(np.array(img_list).shape)\n",
    "        return torch.stack([transforms.functional.to_tensor(pic) for pic in img_list])\n",
    "        # return torch.stack([transforms.functional.to_tensor(img_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoRecord(object):\n",
    "    \"\"\"\n",
    "    Helper class for class VideoFrameDataset. This class\n",
    "    represents a video sample's metadata.\n",
    "\n",
    "    Args:\n",
    "        root_datapath: the system path to the root folder\n",
    "                       of the videos.\n",
    "        row: A list with four or more elements where 1) The first\n",
    "             element is the path to the video sample's frames excluding\n",
    "             the root_datapath prefix 2) The  second element is the starting frame id of the video\n",
    "             3) The third element is the inclusive ending frame id of the video\n",
    "             4) The fourth element is the label index.\n",
    "             5) any following elements are labels in the case of multi-label classification\n",
    "    \"\"\"\n",
    "    def __init__(self, row, root_datapath):\n",
    "        self._data = row\n",
    "        self._path = os.path.join(root_datapath, row[0])\n",
    "\n",
    "\n",
    "    @property\n",
    "    def path(self) -> str:\n",
    "        return self._path\n",
    "\n",
    "    @property\n",
    "    def num_frames(self) -> int:\n",
    "        return self.end_frame - self.start_frame + 1  # +1 because end frame is inclusive\n",
    "    @property\n",
    "    def start_frame(self) -> int:\n",
    "        return int(self._data[1])\n",
    "\n",
    "    @property\n",
    "    def end_frame(self) -> int:\n",
    "        return int(self._data[2])\n",
    "\n",
    "    @property\n",
    "    def label(self) -> Union[int, List[int]]:\n",
    "        # just one label_id\n",
    "        if len(self._data) == 4:\n",
    "            return int(self._data[3])\n",
    "        # sample associated with multiple labels\n",
    "        else:\n",
    "            return [int(label_id) for label_id in self._data[3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFrameDataset(torch.utils.data.Dataset):\n",
    "    r\"\"\"\n",
    "    A highly efficient and adaptable dataset class for videos.\n",
    "    Instead of loading every frame of a video,\n",
    "    loads x RGB frames of a video (sparse temporal sampling) and evenly\n",
    "    chooses those frames from start to end of the video, returning\n",
    "    a list of x PIL images or ``FRAMES x CHANNELS x HEIGHT x WIDTH``\n",
    "    tensors where FRAMES=x if the ``ImglistToTensor()``\n",
    "    transform is used.\n",
    "\n",
    "    More specifically, the frame range [START_FRAME, END_FRAME] is divided into NUM_SEGMENTS\n",
    "    segments and FRAMES_PER_SEGMENT consecutive frames are taken from each segment.\n",
    "\n",
    "    Note:\n",
    "        A demonstration of using this class can be seen\n",
    "        in ``demo.py``\n",
    "        https://github.com/RaivoKoot/Video-Dataset-Loading-Pytorch\n",
    "\n",
    "    Note:\n",
    "        This dataset broadly corresponds to the frame sampling technique\n",
    "        introduced in ``Temporal Segment Networks`` at ECCV2016\n",
    "        https://arxiv.org/abs/1608.00859.\n",
    "\n",
    "\n",
    "    Note:\n",
    "        This class relies on receiving video data in a structure where\n",
    "        inside a ``ROOT_DATA`` folder, each video lies in its own folder,\n",
    "        where each video folder contains the frames of the video as\n",
    "        individual files with a naming convention such as\n",
    "        img_001.jpg ... img_059.jpg.\n",
    "        For enumeration and annotations, this class expects to receive\n",
    "        the path to a .txt file where each video sample has a row with four\n",
    "        (or more in the case of multi-label, see README on Github)\n",
    "        space separated values:\n",
    "        ``VIDEO_FOLDER_PATH     START_FRAME      END_FRAME      LABEL_INDEX``.\n",
    "        ``VIDEO_FOLDER_PATH`` is expected to be the path of a video folder\n",
    "        excluding the ``ROOT_DATA`` prefix. For example, ``ROOT_DATA`` might\n",
    "        be ``home\\data\\datasetxyz\\videos\\``, inside of which a ``VIDEO_FOLDER_PATH``\n",
    "        might be ``jumping\\0052\\`` or ``sample1\\`` or ``00053\\``.\n",
    "\n",
    "    Args:\n",
    "        root_path: The root path in which video folders lie.\n",
    "                   this is ROOT_DATA from the description above.\n",
    "        annotationfile_path: The .txt annotation file containing\n",
    "                             one row per video sample as described above.\n",
    "        num_segments: The number of segments the video should\n",
    "                      be divided into to sample frames from.\n",
    "        frames_per_segment: The number of frames that should\n",
    "                            be loaded per segment. For each segment's\n",
    "                            frame-range, a random start index or the\n",
    "                            center is chosen, from which frames_per_segment\n",
    "                            consecutive frames are loaded.\n",
    "        imagefile_template: The image filename template that video frame files\n",
    "                            have inside of their video folders as described above.\n",
    "        transform: Transform pipeline that receives a list of PIL images/frames.\n",
    "        test_mode: If True, frames are taken from the center of each\n",
    "                   segment, instead of a random location in each segment.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 root_path: str,\n",
    "                 annotationfile_path: str,\n",
    "                 num_segments: int = 3,\n",
    "                 frames_per_segment: int = 1,\n",
    "                 imagefile_template: str='img_{:05d}.jpg',\n",
    "                 transform = None,\n",
    "                 test_mode: bool = False):\n",
    "        super(VideoFrameDataset, self).__init__()\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.annotationfile_path = annotationfile_path\n",
    "        self.num_segments = num_segments\n",
    "        self.frames_per_segment = frames_per_segment\n",
    "        self.imagefile_template = imagefile_template\n",
    "        self.transform = transform\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "        self._parse_annotationfile()\n",
    "        self._sanity_check_samples()\n",
    "\n",
    "    def _load_image(self, directory: str, idx: int) -> Image.Image:\n",
    "        return Image.open(os.path.join(directory, self.imagefile_template.format(idx))).convert('RGB')\n",
    "\n",
    "    def _parse_annotationfile(self):\n",
    "        self.video_list = [VideoRecord(x.strip().split(), self.root_path) for x in open(self.annotationfile_path)]\n",
    "\n",
    "    def _sanity_check_samples(self):\n",
    "        for record in self.video_list:\n",
    "            if record.num_frames <= 0 or record.start_frame == record.end_frame:\n",
    "                print(f\"\\nDataset Warning: video {record.path} seems to have zero RGB frames on disk!\\n\")\n",
    "\n",
    "            elif record.num_frames < (self.num_segments * self.frames_per_segment):\n",
    "                print(f\"\\nDataset Warning: video {record.path} has {record.num_frames} frames \"\n",
    "                      f\"but the dataloader is set up to load \"\n",
    "                      f\"(num_segments={self.num_segments})*(frames_per_segment={self.frames_per_segment})\"\n",
    "                      f\"={self.num_segments * self.frames_per_segment} frames. Dataloader will throw an \"\n",
    "                      f\"error when trying to load this video.\\n\")\n",
    "\n",
    "    def _get_start_indices(self, record: VideoRecord) -> 'np.ndarray[int]':\n",
    "        \"\"\"\n",
    "        For each segment, choose a start index from where frames\n",
    "        are to be loaded from.\n",
    "\n",
    "        Args:\n",
    "            record: VideoRecord denoting a video sample.\n",
    "        Returns:\n",
    "            List of indices of where the frames of each\n",
    "            segment are to be loaded from.\n",
    "        \"\"\"\n",
    "        # choose start indices that are perfectly evenly spread across the video frames.\n",
    "        if self.test_mode:\n",
    "            distance_between_indices = (record.num_frames - self.frames_per_segment + 1) / float(self.num_segments)\n",
    "\n",
    "            start_indices = np.array([int(distance_between_indices / 2.0 + distance_between_indices * x)\n",
    "                                      for x in range(self.num_segments)])\n",
    "        # randomly sample start indices that are approximately evenly spread across the video frames.\n",
    "        else:\n",
    "            max_valid_start_index = (record.num_frames - self.frames_per_segment + 1) // self.num_segments\n",
    "\n",
    "            start_indices = np.multiply(list(range(self.num_segments)), max_valid_start_index) + \\\n",
    "                      np.random.randint(max_valid_start_index, size=self.num_segments)\n",
    "\n",
    "        return start_indices\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Union[\n",
    "        Tuple[List[Image.Image], Union[int, List[int]]],\n",
    "        Tuple['torch.Tensor[num_frames, channels, height, width]', Union[int, List[int]]],\n",
    "        Tuple[Any, Union[int, List[int]]],\n",
    "        ]:\n",
    "        \"\"\"\n",
    "        For video with id idx, loads self.NUM_SEGMENTS * self.FRAMES_PER_SEGMENT\n",
    "        frames from evenly chosen locations across the video.\n",
    "\n",
    "        Args:\n",
    "            idx: Video sample index.\n",
    "        Returns:\n",
    "            A tuple of (video, label). Label is either a single\n",
    "            integer or a list of integers in the case of multiple labels.\n",
    "            Video is either 1) a list of PIL images if no transform is used\n",
    "            2) a batch of shape (NUM_IMAGES x CHANNELS x HEIGHT x WIDTH) in the range [0,1]\n",
    "            if the transform \"ImglistToTensor\" is used\n",
    "            3) or anything else if a custom transform is used.\n",
    "        \"\"\"\n",
    "        record: VideoRecord = self.video_list[idx]\n",
    "\n",
    "        frame_start_indices: 'np.ndarray[int]' = self._get_start_indices(record)\n",
    "\n",
    "        return self._get(record, frame_start_indices)\n",
    "\n",
    "    def _get(self, record: VideoRecord, frame_start_indices: 'np.ndarray[int]') -> Union[\n",
    "        Tuple[List[Image.Image], Union[int, List[int]]],\n",
    "        Tuple['torch.Tensor[num_frames, channels, height, width]', Union[int, List[int]]],\n",
    "        Tuple[Any, Union[int, List[int]]],\n",
    "        ]:\n",
    "        \"\"\"\n",
    "        Loads the frames of a video at the corresponding\n",
    "        indices.\n",
    "\n",
    "        Args:\n",
    "            record: VideoRecord denoting a video sample.\n",
    "            frame_start_indices: Indices from which to load consecutive frames from.\n",
    "        Returns:\n",
    "            A tuple of (video, label). Label is either a single\n",
    "            integer or a list of integers in the case of multiple labels.\n",
    "            Video is either 1) a list of PIL images if no transform is used\n",
    "            2) a batch of shape (NUM_IMAGES x CHANNELS x HEIGHT x WIDTH) in the range [0,1]\n",
    "            if the transform \"ImglistToTensor\" is used\n",
    "            3) or anything else if a custom transform is used.\n",
    "        \"\"\"\n",
    "\n",
    "        frame_start_indices = frame_start_indices + record.start_frame\n",
    "        images = list()\n",
    "\n",
    "        # from each start_index, load self.frames_per_segment\n",
    "        # consecutive frames\n",
    "        for start_index in frame_start_indices:\n",
    "            frame_index = int(start_index)\n",
    "\n",
    "            # load self.frames_per_segment consecutive frames\n",
    "            for _ in range(self.frames_per_segment):\n",
    "                image = self._load_image(record.path, frame_index)\n",
    "                images.append(image)\n",
    "\n",
    "                if frame_index < record.end_frame:\n",
    "                    frame_index += 1\n",
    "\n",
    "        if self.transform is not None:\n",
    "            images = self.transform(images)\n",
    "\n",
    "        return images, record.label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preprocess(size):\n",
    "    preprocess = transforms.Compose([\n",
    "        ImglistToTensor(),  # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
    "        transforms.Resize(size),  # image batch, resize smaller edge to 299\n",
    "        transforms.CenterCrop(size),  # image batch, center crop to square 299x299\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ShiftWithChannelTensor()\n",
    "    ])\n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO   ] [Logger      ] Record log in C:\\Users\\dlrdu\\.kivy\\logs\\kivy_22-06-12_12.txt\n",
      "[INFO   ] [deps        ] Successfully imported \"kivy_deps.angle\" 0.3.2\n",
      "[INFO   ] [deps        ] Successfully imported \"kivy_deps.glew\" 0.3.1\n",
      "[INFO   ] [deps        ] Successfully imported \"kivy_deps.sdl2\" 0.4.5\n",
      "[INFO   ] [Kivy        ] v2.1.0\n",
      "[INFO   ] [Kivy        ] Installed at \"C:\\ProgramData\\Anaconda3\\envs\\python_v\\lib\\site-packages\\kivy\\__init__.py\"\n",
      "[INFO   ] [Python      ] v3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n",
      "[INFO   ] [Python      ] Interpreter at \"C:\\ProgramData\\Anaconda3\\envs\\python_v\\python.exe\"\n",
      "[INFO   ] [Logger      ] Purge log fired. Processing...\n",
      "[INFO   ] [Logger      ] Skipped file C:\\Users\\dlrdu\\.kivy\\logs\\kivy_22-06-06_17.txt, PermissionError(13, '다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다')\n",
      "[INFO   ] [Logger      ] Purge finished!\n",
      "[INFO   ] [Factory     ] 189 symbols loaded\n",
      "[INFO   ] [Image       ] Providers: img_tex, img_dds, img_sdl2, img_pil (img_ffpyplayer ignored)\n",
      "[INFO   ] [Window      ] Provider: sdl2\n",
      "[INFO   ] [GL          ] Using the \"OpenGL\" graphics system\n",
      "[INFO   ] [GL          ] GLEW initialization succeeded\n",
      "[INFO   ] [GL          ] Backend used <glew>\n",
      "[INFO   ] [GL          ] OpenGL version <b'4.5.0 - Build 25.20.100.6577'>\n",
      "[INFO   ] [GL          ] OpenGL vendor <b'Intel'>\n",
      "[INFO   ] [GL          ] OpenGL renderer <b'Intel(R) UHD Graphics 620'>\n",
      "[INFO   ] [GL          ] OpenGL parsed version: 4, 5\n",
      "[INFO   ] [GL          ] Shading version <b'4.50 - Build 25.20.100.6577'>\n",
      "[INFO   ] [GL          ] Texture max size <16384>\n",
      "[INFO   ] [GL          ] Texture max units <32>\n",
      "[INFO   ] [Window      ] auto add sdl2 input provider\n",
      "[INFO   ] [Window      ] virtual keyboard not allowed, single mode, not docked\n",
      "[INFO   ] [Text        ] Provider: sdl2\n",
      "[INFO   ] [KivyMD      ] 0.104.2, git-bc7d1f5, 2021-06-06 (installed at \"C:\\ProgramData\\Anaconda3\\envs\\python_v\\lib\\site-packages\\kivymd\\__init__.py\")\n",
      "[INFO   ] [Audio       ] Providers: audio_sdl2 (audio_ffpyplayer ignored)\n",
      "[INFO   ] [GL          ] NPOT texture support is available\n",
      "[WARNING] Deprecated property \"<VariableListProperty name=padding_x>\" of object \"<kivymd.uix.textfield.MDTextField object at 0x000001C0CE4E9D60>\" was accessed, it will be removed in a future version\n",
      "[INFO   ] [Base        ] Start application main loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background animated\n",
      "card animated\n",
      "str_datetime 2022-06-12\n",
      "daily_time 1740\n",
      "study_screen added\n",
      "Screen [study_screen] added\n",
      "background animated\n",
      "dataset 폴더 안 영상 삭제\n",
      "dataset 폴더 안 영상 삭제\n",
      "dataset 폴더 안 영상 삭제\n",
      "분석시작\n",
      "captured_num 1 영상 분석 -->  data/dataset/video_0001.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0001.mp4', 'video_0002.mp4']\n",
      "files[captured_num-2] video_0001.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [3]\n",
      "행동 -->  using_computer\n",
      "30 행동 15초 추가\n",
      "study_time 15\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 2 영상 분석 -->  data/dataset/video_0002.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0001.mp4', 'video_0002.mp4', 'video_0003.mp4']\n",
      "files[captured_num-2] video_0002.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "30 행동 15초 추가\n",
      "study_time 30\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 3 영상 분석 -->  data/dataset/video_0003.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0001.mp4', 'video_0002.mp4', 'video_0003.mp4', 'video_0004.mp4']\n",
      "영상삭제 ./data/dataset/video_0001.mp4\n",
      "files ['video_0001.mp4', 'video_0002.mp4', 'video_0003.mp4', 'video_0004.mp4']\n",
      "files[captured_num-2] video_0003.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "45 행동 15초 추가\n",
      "study_time 45\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 4 영상 분석 -->  data/dataset/video_0004.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0002.mp4', 'video_0003.mp4', 'video_0004.mp4', 'video_0005.mp4']\n",
      "영상삭제 ./data/dataset/video_0002.mp4\n",
      "files ['video_0002.mp4', 'video_0003.mp4', 'video_0004.mp4', 'video_0005.mp4']\n",
      "files[-2] video_0004.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "60 행동 15초 추가\n",
      "study_time 60\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 5 영상 분석 -->  data/dataset/video_0005.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0003.mp4', 'video_0004.mp4', 'video_0005.mp4', 'video_0006.mp4']\n",
      "영상삭제 ./data/dataset/video_0003.mp4\n",
      "files ['video_0003.mp4', 'video_0004.mp4', 'video_0005.mp4', 'video_0006.mp4']\n",
      "files[-2] video_0005.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "75 행동 15초 추가\n",
      "study_time 75\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 6 영상 분석 -->  data/dataset/video_0006.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0004.mp4', 'video_0005.mp4', 'video_0006.mp4', 'video_0007.mp4']\n",
      "영상삭제 ./data/dataset/video_0004.mp4\n",
      "files ['video_0004.mp4', 'video_0005.mp4', 'video_0006.mp4', 'video_0007.mp4']\n",
      "files[-2] video_0006.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "90 행동 15초 추가\n",
      "study_time 90\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 7 영상 분석 -->  data/dataset/video_0007.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0005.mp4', 'video_0006.mp4', 'video_0007.mp4', 'video_0008.mp4']\n",
      "영상삭제 ./data/dataset/video_0005.mp4\n",
      "files ['video_0005.mp4', 'video_0006.mp4', 'video_0007.mp4', 'video_0008.mp4']\n",
      "files[-2] video_0007.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [4]\n",
      "행동 -->  using_smartphone\n",
      "30 행동 15초 추가\n",
      "notstudy_time 15\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 8 영상 분석 -->  data/dataset/video_0008.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0006.mp4', 'video_0007.mp4', 'video_0008.mp4', 'video_0009.mp4']\n",
      "영상삭제 ./data/dataset/video_0006.mp4\n",
      "files ['video_0006.mp4', 'video_0007.mp4', 'video_0008.mp4', 'video_0009.mp4']\n",
      "files[-2] video_0008.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "105 행동 15초 추가\n",
      "study_time 105\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 9 영상 분석 -->  data/dataset/video_0009.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0007.mp4', 'video_0008.mp4', 'video_0009.mp4', 'video_0010.mp4']\n",
      "영상삭제 ./data/dataset/video_0007.mp4\n",
      "files ['video_0007.mp4', 'video_0008.mp4', 'video_0009.mp4', 'video_0010.mp4']\n",
      "files[-2] video_0009.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "120 행동 15초 추가\n",
      "study_time 120\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 10 영상 분석 -->  data/dataset/video_0010.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0008.mp4', 'video_0009.mp4', 'video_0010.mp4', 'video_0011.mp4']\n",
      "영상삭제 ./data/dataset/video_0008.mp4\n",
      "files ['video_0008.mp4', 'video_0009.mp4', 'video_0010.mp4', 'video_0011.mp4']\n",
      "files[-2] video_0010.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [1]\n",
      "행동 -->  reading\n",
      "30 행동 15초 추가\n",
      "study_time 135\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 11 영상 분석 -->  data/dataset/video_0011.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0009.mp4', 'video_0010.mp4', 'video_0011.mp4', 'video_0012.mp4']\n",
      "영상삭제 ./data/dataset/video_0009.mp4\n",
      "files ['video_0009.mp4', 'video_0010.mp4', 'video_0011.mp4', 'video_0012.mp4']\n",
      "files[-2] video_0011.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [1]\n",
      "행동 -->  reading\n",
      "45 행동 15초 추가\n",
      "study_time 150\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 12 영상 분석 -->  data/dataset/video_0012.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0010.mp4', 'video_0011.mp4', 'video_0012.mp4', 'video_0013.mp4']\n",
      "영상삭제 ./data/dataset/video_0010.mp4\n",
      "files ['video_0010.mp4', 'video_0011.mp4', 'video_0012.mp4', 'video_0013.mp4']\n",
      "files[-2] video_0012.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [1]\n",
      "행동 -->  reading\n",
      "60 행동 15초 추가\n",
      "study_time 165\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 13 영상 분석 -->  data/dataset/video_0013.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0011.mp4', 'video_0012.mp4', 'video_0013.mp4', 'video_0014.mp4']\n",
      "영상삭제 ./data/dataset/video_0011.mp4\n",
      "files ['video_0011.mp4', 'video_0012.mp4', 'video_0013.mp4', 'video_0014.mp4']\n",
      "files[-2] video_0013.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [3]\n",
      "행동 -->  using_computer\n",
      "45 행동 15초 추가\n",
      "study_time 180\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 14 영상 분석 -->  data/dataset/video_0014.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0012.mp4', 'video_0013.mp4', 'video_0014.mp4', 'video_0015.mp4']\n",
      "영상삭제 ./data/dataset/video_0012.mp4\n",
      "files ['video_0012.mp4', 'video_0013.mp4', 'video_0014.mp4', 'video_0015.mp4']\n",
      "files[-2] video_0014.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "135 행동 15초 추가\n",
      "study_time 195\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 15 영상 분석 -->  data/dataset/video_0015.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0013.mp4', 'video_0014.mp4', 'video_0015.mp4', 'video_0016.mp4']\n",
      "영상삭제 ./data/dataset/video_0013.mp4\n",
      "files ['video_0013.mp4', 'video_0014.mp4', 'video_0015.mp4', 'video_0016.mp4']\n",
      "files[-2] video_0015.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "150 행동 15초 추가\n",
      "study_time 210\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 16 영상 분석 -->  data/dataset/video_0016.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0014.mp4', 'video_0015.mp4', 'video_0016.mp4', 'video_0017.mp4']\n",
      "영상삭제 ./data/dataset/video_0014.mp4\n",
      "files ['video_0014.mp4', 'video_0015.mp4', 'video_0016.mp4', 'video_0017.mp4']\n",
      "files[-2] video_0016.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "165 행동 15초 추가\n",
      "study_time 225\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 17 영상 분석 -->  data/dataset/video_0017.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0015.mp4', 'video_0016.mp4', 'video_0017.mp4', 'video_0018.mp4']\n",
      "영상삭제 ./data/dataset/video_0015.mp4\n",
      "files ['video_0015.mp4', 'video_0016.mp4', 'video_0017.mp4', 'video_0018.mp4']\n",
      "files[-2] video_0017.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "180 행동 15초 추가\n",
      "study_time 240\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 18 영상 분석 -->  data/dataset/video_0018.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0016.mp4', 'video_0017.mp4', 'video_0018.mp4', 'video_0019.mp4']\n",
      "영상삭제 ./data/dataset/video_0016.mp4\n",
      "files ['video_0016.mp4', 'video_0017.mp4', 'video_0018.mp4', 'video_0019.mp4']\n",
      "files[-2] video_0018.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [4]\n",
      "행동 -->  using_smartphone\n",
      "45 행동 15초 추가\n",
      "notstudy_time 30\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 19 영상 분석 -->  data/dataset/video_0019.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0017.mp4', 'video_0018.mp4', 'video_0019.mp4', 'video_0020.mp4']\n",
      "영상삭제 ./data/dataset/video_0017.mp4\n",
      "files ['video_0017.mp4', 'video_0018.mp4', 'video_0019.mp4', 'video_0020.mp4']\n",
      "files[-2] video_0019.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "195 행동 15초 추가\n",
      "study_time 255\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 20 영상 분석 -->  data/dataset/video_0020.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0018.mp4', 'video_0019.mp4', 'video_0020.mp4', 'video_0021.mp4']\n",
      "영상삭제 ./data/dataset/video_0018.mp4\n",
      "files ['video_0018.mp4', 'video_0019.mp4', 'video_0020.mp4', 'video_0021.mp4']\n",
      "files[-2] video_0020.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "210 행동 15초 추가\n",
      "study_time 270\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 21 영상 분석 -->  data/dataset/video_0021.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0019.mp4', 'video_0020.mp4', 'video_0021.mp4', 'video_0022.mp4']\n",
      "영상삭제 ./data/dataset/video_0019.mp4\n",
      "files ['video_0019.mp4', 'video_0020.mp4', 'video_0021.mp4', 'video_0022.mp4']\n",
      "files[-2] video_0021.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "225 행동 15초 추가\n",
      "study_time 285\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 22 영상 분석 -->  data/dataset/video_0022.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0020.mp4', 'video_0021.mp4', 'video_0022.mp4', 'video_0023.mp4']\n",
      "영상삭제 ./data/dataset/video_0020.mp4\n",
      "files ['video_0020.mp4', 'video_0021.mp4', 'video_0022.mp4', 'video_0023.mp4']\n",
      "files[-2] video_0022.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "240 행동 15초 추가\n",
      "study_time 300\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 23 영상 분석 -->  data/dataset/video_0023.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0021.mp4', 'video_0022.mp4', 'video_0023.mp4', 'video_0024.mp4']\n",
      "영상삭제 ./data/dataset/video_0021.mp4\n",
      "files ['video_0021.mp4', 'video_0022.mp4', 'video_0023.mp4', 'video_0024.mp4']\n",
      "files[-2] video_0023.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "30 행동 15초 추가\n",
      "notstudy_time 45\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 24 영상 분석 -->  data/dataset/video_0024.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0022.mp4', 'video_0023.mp4', 'video_0024.mp4', 'video_0025.mp4']\n",
      "영상삭제 ./data/dataset/video_0022.mp4\n",
      "files ['video_0022.mp4', 'video_0023.mp4', 'video_0024.mp4', 'video_0025.mp4']\n",
      "files[-2] video_0024.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "255 행동 15초 추가\n",
      "study_time 315\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 25 영상 분석 -->  data/dataset/video_0025.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0023.mp4', 'video_0024.mp4', 'video_0025.mp4', 'video_0026.mp4']\n",
      "영상삭제 ./data/dataset/video_0023.mp4\n",
      "files ['video_0023.mp4', 'video_0024.mp4', 'video_0025.mp4', 'video_0026.mp4']\n",
      "files[-2] video_0025.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "270 행동 15초 추가\n",
      "study_time 330\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 26 영상 분석 -->  data/dataset/video_0026.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0024.mp4', 'video_0025.mp4', 'video_0026.mp4', 'video_0027.mp4']\n",
      "영상삭제 ./data/dataset/video_0024.mp4\n",
      "files ['video_0024.mp4', 'video_0025.mp4', 'video_0026.mp4', 'video_0027.mp4']\n",
      "files[-2] video_0026.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "45 행동 15초 추가\n",
      "notstudy_time 60\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 27 영상 분석 -->  data/dataset/video_0027.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0025.mp4', 'video_0026.mp4', 'video_0027.mp4', 'video_0028.mp4']\n",
      "영상삭제 ./data/dataset/video_0025.mp4\n",
      "files ['video_0025.mp4', 'video_0026.mp4', 'video_0027.mp4', 'video_0028.mp4']\n",
      "files[-2] video_0027.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "285 행동 15초 추가\n",
      "study_time 345\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 28 영상 분석 -->  data/dataset/video_0028.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0026.mp4', 'video_0027.mp4', 'video_0028.mp4', 'video_0029.mp4']\n",
      "영상삭제 ./data/dataset/video_0026.mp4\n",
      "files ['video_0026.mp4', 'video_0027.mp4', 'video_0028.mp4', 'video_0029.mp4']\n",
      "files[-2] video_0028.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "60 행동 15초 추가\n",
      "notstudy_time 75\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 29 영상 분석 -->  data/dataset/video_0029.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0027.mp4', 'video_0028.mp4', 'video_0029.mp4', 'video_0030.mp4']\n",
      "영상삭제 ./data/dataset/video_0027.mp4\n",
      "files ['video_0027.mp4', 'video_0028.mp4', 'video_0029.mp4', 'video_0030.mp4']\n",
      "files[-2] video_0029.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "75 행동 15초 추가\n",
      "notstudy_time 90\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 30 영상 분석 -->  data/dataset/video_0030.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0028.mp4', 'video_0029.mp4', 'video_0030.mp4', 'video_0031.mp4']\n",
      "영상삭제 ./data/dataset/video_0028.mp4\n",
      "files ['video_0028.mp4', 'video_0029.mp4', 'video_0030.mp4', 'video_0031.mp4']\n",
      "files[-2] video_0030.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "90 행동 15초 추가\n",
      "notstudy_time 105\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 31 영상 분석 -->  data/dataset/video_0031.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0029.mp4', 'video_0030.mp4', 'video_0031.mp4', 'video_0032.mp4']\n",
      "영상삭제 ./data/dataset/video_0029.mp4\n",
      "files ['video_0029.mp4', 'video_0030.mp4', 'video_0031.mp4', 'video_0032.mp4']\n",
      "files[-2] video_0031.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [5]\n",
      "행동 -->  writing\n",
      "300 행동 15초 추가\n",
      "study_time 360\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 32 영상 분석 -->  data/dataset/video_0032.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0030.mp4', 'video_0031.mp4', 'video_0032.mp4', 'video_0033.mp4']\n",
      "영상삭제 ./data/dataset/video_0030.mp4\n",
      "files ['video_0030.mp4', 'video_0031.mp4', 'video_0032.mp4', 'video_0033.mp4']\n",
      "files[-2] video_0032.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "105 행동 15초 추가\n",
      "notstudy_time 120\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 33 영상 분석 -->  data/dataset/video_0033.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0031.mp4', 'video_0032.mp4', 'video_0033.mp4', 'video_0034.mp4']\n",
      "영상삭제 ./data/dataset/video_0031.mp4\n",
      "files ['video_0031.mp4', 'video_0032.mp4', 'video_0033.mp4', 'video_0034.mp4']\n",
      "files[-2] video_0033.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "120 행동 15초 추가\n",
      "notstudy_time 135\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 34 영상 분석 -->  data/dataset/video_0034.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0032.mp4', 'video_0033.mp4', 'video_0034.mp4', 'video_0035.mp4']\n",
      "영상삭제 ./data/dataset/video_0032.mp4\n",
      "files ['video_0032.mp4', 'video_0033.mp4', 'video_0034.mp4', 'video_0035.mp4']\n",
      "files[-2] video_0034.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "135 행동 15초 추가\n",
      "notstudy_time 150\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 35 영상 분석 -->  data/dataset/video_0035.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0033.mp4', 'video_0034.mp4', 'video_0035.mp4', 'video_0036.mp4']\n",
      "영상삭제 ./data/dataset/video_0033.mp4\n",
      "files ['video_0033.mp4', 'video_0034.mp4', 'video_0035.mp4', 'video_0036.mp4']\n",
      "files[-2] video_0035.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "150 행동 15초 추가\n",
      "notstudy_time 165\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 36 영상 분석 -->  data/dataset/video_0036.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0034.mp4', 'video_0035.mp4', 'video_0036.mp4', 'video_0037.mp4']\n",
      "영상삭제 ./data/dataset/video_0034.mp4\n",
      "files ['video_0034.mp4', 'video_0035.mp4', 'video_0036.mp4', 'video_0037.mp4']\n",
      "files[-2] video_0036.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "165 행동 15초 추가\n",
      "notstudy_time 180\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 37 영상 분석 -->  data/dataset/video_0037.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0035.mp4', 'video_0036.mp4', 'video_0037.mp4', 'video_0038.mp4']\n",
      "영상삭제 ./data/dataset/video_0035.mp4\n",
      "files ['video_0035.mp4', 'video_0036.mp4', 'video_0037.mp4', 'video_0038.mp4']\n",
      "files[-2] video_0037.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "180 행동 15초 추가\n",
      "notstudy_time 195\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 38 영상 분석 -->  data/dataset/video_0038.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0036.mp4', 'video_0037.mp4', 'video_0038.mp4', 'video_0039.mp4']\n",
      "영상삭제 ./data/dataset/video_0036.mp4\n",
      "files ['video_0036.mp4', 'video_0037.mp4', 'video_0038.mp4', 'video_0039.mp4']\n",
      "files[-2] video_0038.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "195 행동 15초 추가\n",
      "notstudy_time 210\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 39 영상 분석 -->  data/dataset/video_0039.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0037.mp4', 'video_0038.mp4', 'video_0039.mp4', 'video_0040.mp4']\n",
      "영상삭제 ./data/dataset/video_0037.mp4\n",
      "files ['video_0037.mp4', 'video_0038.mp4', 'video_0039.mp4', 'video_0040.mp4']\n",
      "files[-2] video_0039.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "210 행동 15초 추가\n",
      "notstudy_time 225\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 40 영상 분석 -->  data/dataset/video_0040.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0038.mp4', 'video_0039.mp4', 'video_0040.mp4', 'video_0041.mp4']\n",
      "영상삭제 ./data/dataset/video_0038.mp4\n",
      "files ['video_0038.mp4', 'video_0039.mp4', 'video_0040.mp4', 'video_0041.mp4']\n",
      "files[-2] video_0040.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "225 행동 15초 추가\n",
      "notstudy_time 240\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 41 영상 분석 -->  data/dataset/video_0041.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0039.mp4', 'video_0040.mp4', 'video_0041.mp4', 'video_0042.mp4']\n",
      "영상삭제 ./data/dataset/video_0039.mp4\n",
      "files ['video_0039.mp4', 'video_0040.mp4', 'video_0041.mp4', 'video_0042.mp4']\n",
      "files[-2] video_0041.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "240 행동 15초 추가\n",
      "notstudy_time 255\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 42 영상 분석 -->  data/dataset/video_0042.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0040.mp4', 'video_0041.mp4', 'video_0042.mp4', 'video_0043.mp4']\n",
      "영상삭제 ./data/dataset/video_0040.mp4\n",
      "files ['video_0040.mp4', 'video_0041.mp4', 'video_0042.mp4', 'video_0043.mp4']\n",
      "files[-2] video_0042.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "255 행동 15초 추가\n",
      "notstudy_time 270\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 43 영상 분석 -->  data/dataset/video_0043.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0041.mp4', 'video_0042.mp4', 'video_0043.mp4', 'video_0044.mp4']\n",
      "영상삭제 ./data/dataset/video_0041.mp4\n",
      "files ['video_0041.mp4', 'video_0042.mp4', 'video_0043.mp4', 'video_0044.mp4']\n",
      "files[-2] video_0043.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "270 행동 15초 추가\n",
      "notstudy_time 285\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 44 영상 분석 -->  data/dataset/video_0044.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0042.mp4', 'video_0043.mp4', 'video_0044.mp4', 'video_0045.mp4']\n",
      "영상삭제 ./data/dataset/video_0042.mp4\n",
      "files ['video_0042.mp4', 'video_0043.mp4', 'video_0044.mp4', 'video_0045.mp4']\n",
      "files[-2] video_0044.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "285 행동 15초 추가\n",
      "notstudy_time 300\n",
      "분석종료 analysis_num 0\n",
      "분석시작\n",
      "captured_num 45 영상 분석 -->  data/dataset/video_0045.mp4\n",
      "path data subdirs ['.ipynb_checkpoints', 'dataset'] files []\n",
      "path data\\.ipynb_checkpoints subdirs [] files []\n",
      "path data\\dataset subdirs [] files ['video_0043.mp4', 'video_0044.mp4', 'video_0045.mp4', 'video_0046.mp4']\n",
      "영상삭제 ./data/dataset/video_0043.mp4\n",
      "files ['video_0043.mp4', 'video_0044.mp4', 'video_0045.mp4', 'video_0046.mp4']\n",
      "files[-2] video_0045.mp4\n",
      "Currently have 1 video data...\n",
      "y_pred [0]\n",
      "행동 -->  leaving_seat\n",
      "300 행동 15초 추가\n",
      "notstudy_time 315\n",
      "분석종료 analysis_num 0\n",
      "str_datetime 2022-06-12\n",
      "최종집중시간 360\n",
      "최종비집중시간 315\n",
      "month_time 2730\n",
      "week 23\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "iso_calendar[1] 21\n",
      "week 23 <class 'int'>\n",
      "week_time 0\n",
      "str_datetime 2022-06-12\n",
      "daily_time 2100\n",
      "registration_screen added\n",
      "Screen [registration_screen] added\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background animated\n",
      "background animated\n",
      "Screen [registration_screen] already exists\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background animated\n",
      "background animated\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "from kivy.app import App\n",
    "from kivy.core.window import Window\n",
    "from kivy.lang import Builder\n",
    "from kivy.uix.screenmanager import Screen, ScreenManager\n",
    "from kivy.factory import Factory\n",
    "from kivy.animation import Animation\n",
    "from kivy.uix.boxlayout import BoxLayout\n",
    "from kivy.properties import ListProperty\n",
    "from kivy.metrics import dp\n",
    "from kivy.uix.button import Button\n",
    "from kivy.uix.behaviors import ButtonBehavior\n",
    "from kivymd.uix.behaviors import CircularRippleBehavior\n",
    "from kivymd.toast.kivytoast.kivytoast import toast\n",
    "from kivy.core.audio import SoundLoader\n",
    "\n",
    "from kivymd.app import MDApp\n",
    "from kivymd.uix.bottomnavigation import MDBottomNavigationItem\n",
    "from kivymd.uix.card import MDCard\n",
    "\n",
    "from tkinter import messagebox as msg\n",
    "from tkinter import Tk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from kivy.uix.floatlayout import FloatLayout\n",
    "from kivy.garden.matplotlib.backend_kivyagg import FigureCanvasKivyAgg\n",
    "from kivy.uix.image import Image\n",
    "from PIL import Image\n",
    "\n",
    "from kivy.config import Config\n",
    "Config.set('graphics', 'fullscreen','0')\n",
    "\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "Window.softinput_mode = \"below_target\"  # resize to accomodate keyboard\n",
    "Window.keyboard_anim_args = {'d': 0.5, 't': 'in_out_quart'}\n",
    "\n",
    "Builder.load_string(\"\"\"\n",
    "#:import utils kivy.utils\n",
    "#:include kv/login.kv\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "class JobListScreen(Screen):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def on_enter(self):\n",
    "        for _ in range(10):\n",
    "            MDApp.get_running_app().job_list.append({\"height\": dp(150)})\n",
    "\n",
    "\n",
    "class JobListCard(MDCard):\n",
    "    def prepare_viewing_of_publication(self):\n",
    "        print(int(self.publication_id))\n",
    "    def view_job(self, job_card):\n",
    "        print(job_card)\n",
    "    \n",
    "    def toggle_heart(self, widget):\n",
    "        if widget.icon == \"heart\":\n",
    "            widget.icon = \"heart-outline\" if widget.icon == \"heart\" else \"heart-outline\"\n",
    "            toast(\"Job unsaved\")\n",
    "        else:\n",
    "            widget.icon = \"heart\" if widget.icon == \"heart-outline\" else \"heart\"\n",
    "            toast(\"Job saved\")\n",
    "\n",
    "\n",
    "class HomeScreen(Screen):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def on_enter(self):\n",
    "        MDApp.get_running_app().category_list.append({\"height\": dp(150)})\n",
    "        MDApp.get_running_app().category_list.append({\"height\": dp(150)})\n",
    "        MDApp.get_running_app().category_list.append({\"height\": dp(150)})\n",
    "        MDApp.get_running_app().category_list.append({\"height\": dp(150)})\n",
    "        MDApp.get_running_app().category_list.append({\"height\": dp(150)})\n",
    "\n",
    "class CategoryCard(MDCard,CircularRippleBehavior, ButtonBehavior):\n",
    "    def open_category(self, widget):\n",
    "        print(widget)\n",
    "    def on_release(self):\n",
    "        MDApp.get_running_app().manage_screens(\"job_list_screen\", \"add\")\n",
    "        MDApp.get_running_app().change_screen(\"job_list_screen\")\n",
    "\n",
    "class Emp(MDApp):\n",
    "    job_list = ListProperty() # contains data needed to display job list cards\n",
    "    category_list = ListProperty() # contains data needed to display job list cards\n",
    "    global study_time\n",
    "    global notstudy_time\n",
    "    global writing\n",
    "    global reading\n",
    "    global using_computer\n",
    "    global leaving_seat\n",
    "    global sleeping\n",
    "    global using_smartphone\n",
    "    #global graph_1\n",
    "    #graph_1 = MDApp.get_running_app().get_screen('registration_screen')  \n",
    "    \n",
    "    writing = 15\n",
    "    reading = 15\n",
    "    using_computer = 15\n",
    "    leaving_seat = 15\n",
    "    sleeping = 15\n",
    "    using_smartphone = 15\n",
    "    study_time = 0\n",
    "    notstudy_time = 0\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.title = \"Fourstars Study\"\n",
    "        self.theme_cls.primary_palette = \"DeepPurple\"\n",
    "        self.theme_cls.theme_style = \"Light\"\n",
    "        self.sm = ScreenManager()\n",
    "        self.has_animated_card = False\n",
    "        self.has_animated_background = False\n",
    "    \n",
    "    def account_action(self, email, passwd, username=None, action=None):\n",
    "        print(email, passwd, username, action)\n",
    "        if action == \"register\":\n",
    "            pass\n",
    "            # register the user\n",
    "        elif action == \"login\":\n",
    "            # login the user\n",
    "            pass\n",
    "        self.manage_screens(\"home_screen\", \"add\")\n",
    "        self.change_screen(\"home_screen\")\n",
    "\n",
    "    def animate_background(self, widget):\n",
    "        if self.has_animated_background == False:\n",
    "            anim = Animation(size_hint_y=1) + Animation(size_hint_y=0.5)\n",
    "            anim.start(widget.ids.bx)\n",
    "            print(\"background animated\")\n",
    "        else:\n",
    "            print(\"background already animated\")\n",
    "    \n",
    "    def animate_card(self, widget):\n",
    "        # {\"center_x\": 0.5, \"center_y\": 0.6}\n",
    "        if self.has_animated_card == False:\n",
    "            anim = Animation(pos_hint={\"center_x\": 0.5, \"center_y\": 0.6}, duration=2)\n",
    "            anim.start(widget)\n",
    "            self.has_animated_card = True\n",
    "            print(\"card animated\")\n",
    "        else:\n",
    "            print(\"card already animated\")\n",
    "\n",
    "    def change_screen(self, screen_name):\n",
    "        if self.sm.has_screen(screen_name):\n",
    "            self.sm.current = screen_name\n",
    "        else:\n",
    "            print(\"Screen [\" + screen_name + \"] does not exist.\")\n",
    "\n",
    "    def manage_screens(self, screen_name, action):\n",
    "        scns = {\n",
    "            \"study_screen\": Factory.StudyScreen,\n",
    "            \"login_screen\": Factory.LoginScreen,\n",
    "            \"registration_screen\": Factory.RegistrationScreen,\n",
    "            \"home_screen\": Factory.HomeScreen,\n",
    "            \"job_list_screen\": Factory.JobListScreen\n",
    "        }\n",
    "        try:\n",
    "\n",
    "            if action == \"remove\":\n",
    "                if self.sm.has_screen(screen_name):\n",
    "                    self.sm.remove_widget(self.sm.get_screen(screen_name))\n",
    "                print(\"Screen [\"+screen_name+\"] removed\")\n",
    "            elif action == \"add\":\n",
    "                if self.sm.has_screen(screen_name):\n",
    "                    print(\"Screen [\" + screen_name + \"] already exists\")\n",
    "                else:\n",
    "                    self.sm.add_widget(scns[screen_name](name=screen_name))\n",
    "                    print(screen_name + \" added\")\n",
    "                    print(\"Screen [\"+screen_name+\"] added\")\n",
    "        except:\n",
    "            print(traceback.format_exc())\n",
    "            print(\"Traceback ^.^\")\n",
    "\n",
    "    def on_pause(self):\n",
    "        return True\n",
    "\n",
    "    def on_resume(self):\n",
    "        pass\n",
    "    \n",
    "    def update(self):\n",
    "        global study_time\n",
    "        global notstudy_time\n",
    "        #분석전 test폴더 있으면 삭제한다\n",
    "        if os.path.exists(r\"./data/test\") == True :\n",
    "            print('test 폴더 삭제')\n",
    "            shutil.rmtree(\"./data/test\")\n",
    "        #분석전 dataset폴더 안에 저장된 영상 있으면 삭제한다    \n",
    "        for file in os.scandir('./data/dataset'):\n",
    "            os.remove(file.path)\n",
    "            print('dataset 폴더 안 영상 삭제')\n",
    "    \n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"Camera open failed!\")\n",
    "            sys.exit()\n",
    "            \n",
    "        w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS) # 카메라에 따라 값이 정상적, 비정상적\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "        delay = round(1000/fps)\n",
    "        \n",
    "        captured_num=1\n",
    "        analysis_num=0\n",
    "        alarm_notstudy = 0\n",
    "        out = cv2.VideoWriter('data/dataset/video_{:04d}.mp4'.format(captured_num), fourcc, fps, (w, h))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            print('File open failed!')\n",
    "            cap.release()\n",
    "            sys.exit()\n",
    "            \n",
    "        sample_num = 0\n",
    "        record = False\n",
    "        \n",
    "        while True:                 # 무한 루프\n",
    "            ret, frame = cap.read() # 카메라의 ret, frame 값 받아오기\n",
    "            sample_num = sample_num + 1\n",
    "\n",
    "            if not ret:             #ret이 False면 중지\n",
    "                break\n",
    "\n",
    "            cv2.imshow('frame', frame)\n",
    "            \n",
    "            if analysis_num == 1:\n",
    "                print('분석시작')\n",
    "                \n",
    "                print('captured_num',captured_num-1,'영상 분석 --> ','data/dataset/video_{:04d}.mp4'.format(captured_num-1))\n",
    "                \n",
    "                v_l = cv2.VideoCapture('data/dataset/video_{:04d}.mp4'.format(captured_num-1))\n",
    "\n",
    "                if not v_l.isOpened():\n",
    "                    print(\"could not open :\", 'data/dataset/video_{:04d}.mp4'.format(captured_num-1))\n",
    "                    exit(0)\n",
    "\n",
    "                length = int(v_l.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                # print('video length',length)\n",
    "\n",
    "                if length > 90:\n",
    "                    def check_mkdir(dir_name):\n",
    "                        if not os.path.exists(dir_name):\n",
    "                            os.mkdir(dir_name)\n",
    "\n",
    "                    def create_frames_from_video(video_location, save_folder ,name_prefix='img', extension='jpg'):\n",
    "                        # Read the video from specified path\n",
    "                        cam = cv2.VideoCapture(video_location)\n",
    "                        currentframe = 1\n",
    "                        while(True):\n",
    "                            # reading from frame\n",
    "                            ret,frame = cam.read()\n",
    "                            if ret:\n",
    "                                # if video is still left continue creating images\n",
    "                                name= os.path.join(save_folder, f'{name_prefix}_{currentframe:05d}.{extension}')\n",
    "\n",
    "                                # writing the extracted images\n",
    "                                cv2.imwrite(name, frame)\n",
    "\n",
    "                                # increasing counter so that it will\n",
    "                                # show how many frames are created\n",
    "                                currentframe += 1\n",
    "                            else:\n",
    "                                break\n",
    "\n",
    "                        cam.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                        return currentframe\n",
    "\n",
    "                    def plot_video(rows, cols, frame_list, plot_width, plot_height, title: str):\n",
    "                        fig = plt.figure(figsize=(plot_width, plot_height))\n",
    "                        grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                                         nrows_ncols=(rows, cols),  # creates 2x2 grid of axes\n",
    "                                         axes_pad=0.3,  # pad between axes in inch.\n",
    "                                         )\n",
    "\n",
    "                        for index, (ax, im) in enumerate(zip(grid, frame_list)):\n",
    "                            # Iterating over the grid returns the Axes.\n",
    "                            ax.imshow(im)\n",
    "                            ax.set_title(index)\n",
    "                        plt.suptitle(title)\n",
    "                        plt.show()\n",
    "\n",
    "                    def denormalize(video_tensor):\n",
    "                        \"\"\"\n",
    "                        Undoes mean/standard deviation normalization, zero to one scaling,\n",
    "                        and channel rearrangement for a batch of images.\n",
    "                        args:\n",
    "                            video_tensor: a (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
    "                        \"\"\"\n",
    "                        inverse_normalize = transforms.Normalize(\n",
    "                            mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225],\n",
    "                            std=[1 / 0.229, 1 / 0.224, 1 / 0.225]\n",
    "                        )\n",
    "                        return (inverse_normalize(video_tensor) * 255.).type(torch.uint8).permute(0, 2, 3, 1).numpy()\n",
    "\n",
    "                    class ShiftWithChannelTensor:\n",
    "                        def __call__(self, data):\n",
    "                            return data.permute(1, 0, 2, 3).contiguous()\n",
    "\n",
    "                        def __repr__(self):\n",
    "                            return self.__class__.__name__ + '()'\n",
    "\n",
    "                    DATA_PATH = 'data'\n",
    "                    # create dictionary of activities\n",
    "\n",
    "                    list_activities= os.listdir(DATA_PATH)\n",
    "                    list_dict= {}\n",
    "                    for index,activity in enumerate(list_activities):\n",
    "                        list_dict[activity] = index\n",
    "\n",
    "                    # create list of data\n",
    "                    all_x =[]\n",
    "                    all_y = []\n",
    "                    for path, subdirs, files in os.walk(DATA_PATH):\n",
    "                        print('path',path,'subdirs',subdirs,'files',files)\n",
    "                        # for name in files:\n",
    "                        #     all_x.append(os.path.join(path, name))\n",
    "                        #     all_y.append(list_dict[basename(normpath(path))])\n",
    "                    # print('captured_num',captured_num)\n",
    "                    # print('files[captured_num - 2]',files[captured_num - 2])\n",
    "                    \n",
    "                    if len(files) > 3:\n",
    "                        print('영상삭제',\"./data/dataset/video_{:04d}.mp4\".format(captured_num-3))\n",
    "                        os.remove(\"./data/dataset/video_{:04d}.mp4\".format(captured_num-3))\n",
    "                        print('files',files)\n",
    "                        \n",
    "                    #여기서 에러나면 checkipynb폴더 생겼는지 확인하고 삭제해라\n",
    "                    if captured_num < 5:\n",
    "                        print('files[captured_num-2]',files[captured_num-2])\n",
    "                        all_x.append(os.path.join(path, files[captured_num-2]))\n",
    "                    else:\n",
    "                        print('files[-2]',files[-2])\n",
    "                        all_x.append(os.path.join(path, files[-2]))\n",
    "                    all_y.append(list_dict[basename(normpath(path))])\n",
    "\n",
    "                    print(f\"Currently have {len(all_x)} video data...\")  \n",
    "\n",
    "                    # generate image for train & test\n",
    "                    check_mkdir('data/test')\n",
    "\n",
    "                    for key,value in list_dict.items():\n",
    "                        check_mkdir(os.path.join('data/test',str(value)))\n",
    "\n",
    "                    with open('data/test/annotations.txt', 'w') as f:\n",
    "                        for index,video in enumerate(all_x):\n",
    "                            vid_in_folder = len(os.listdir(os.path.join('data/test',str(all_y[index]))))\n",
    "                            path_folder = os.path.join('data/test',str(all_y[index]),str(vid_in_folder+1).zfill(5))\n",
    "                            check_mkdir(path_folder)\n",
    "                            # parse video into frame\n",
    "                            last_frame = create_frames_from_video(video,path_folder)\n",
    "                            # create note\n",
    "                            f.write(f'{all_y[index]}/{str(vid_in_folder+1).zfill(5)} 1 {last_frame-1} {all_y[index]}')\n",
    "                            f.write('\\n')\n",
    "\n",
    "                    def eval_preprocess(size):\n",
    "                        preprocess = transforms.Compose([\n",
    "                            ImglistToTensor(),  # list of PIL images to (FRAMES x CHANNELS x HEIGHT x WIDTH) tensor\n",
    "                            transforms.Resize(size),  # image batch, resize smaller edge to 299\n",
    "                            transforms.CenterCrop(size),  # image batch, center crop to square 299x299\n",
    "                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                            ShiftWithChannelTensor()\n",
    "                        ])\n",
    "                        return preprocess\n",
    "\n",
    "                    n_epochs= 80\n",
    "                    train_on_gpu = False\n",
    "                    size = 112\n",
    "\n",
    "                    eval_preprocess = eval_preprocess(size)\n",
    "\n",
    "                    test_dataset = VideoFrameDataset(\n",
    "                        root_path='data/test',\n",
    "                        annotationfile_path='data/test/annotations.txt',\n",
    "                        num_segments=1,\n",
    "                        frames_per_segment=16,\n",
    "                        imagefile_template='img_{:05d}.jpg',\n",
    "                        transform=eval_preprocess,\n",
    "                        test_mode=False\n",
    "                    )\n",
    "\n",
    "                    test_dataloader = torch.utils.data.DataLoader(\n",
    "                        dataset=test_dataset,\n",
    "                        batch_size=8,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0,#2\n",
    "                        pin_memory=True\n",
    "                    )\n",
    "\n",
    "\n",
    "                    # Load torch model\n",
    "                    PATH = 'model/transfer_mobilenet.pt'\n",
    "                    device = torch.device('cpu')\n",
    "                    model = MobileNetV2(num_classes=6, sample_size=size, width_mult=1.)\n",
    "                    model.load_state_dict(torch.load(PATH, map_location=device),strict=False)\n",
    "\n",
    "                    '''PATH = 'model_state_dict.pt'\n",
    "                    device = torch.device('cuda')\n",
    "                    model = MobileNetV2(num_classes=6, sample_size=size, width_mult=1.0)\n",
    "                    model.load_state_dict(torch.load(PATH),strict=False)\n",
    "                    model.to(device)\n",
    "                    '''\n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "                    scheduler = ReduceLROnPlateau(optimizer, 'min',patience=10,verbose=True,min_lr=1e-10)\n",
    "\n",
    "                    ######################    \n",
    "                    # validate the model #\n",
    "                    ######################\n",
    "                    model.eval()\n",
    "                    y_pred = np.array([],dtype='i')\n",
    "                    y_truth = np.array([],dtype='i')\n",
    "                    # print('validation')\n",
    "                    for data, target in test_dataloader:\n",
    "                        output = model(data)\n",
    "                        # print('output', output)\n",
    "                        y_pred = np.concatenate((y_pred, np.argmax(output.clone().detach().cpu().numpy(),axis=1)))\n",
    "                    np.argmax(output.clone().detach().cpu().numpy(),axis=1)\n",
    "                    print('y_pred',y_pred)\n",
    "                    \n",
    "                    ##폴더,분석한 영상 삭제\n",
    "                    shutil.rmtree(\"./data/test\")\n",
    "                    \n",
    "                    label_dict = {'leaving_seat': 0, 'reading': 1, 'sleeping': 2, 'using_computer': 3, 'using_smartphone': 4, 'writing': 5}\n",
    "                    for key, value in label_dict.items():\n",
    "                        if value == y_pred[0]:\n",
    "                            activity_label = key\n",
    "                    print('행동 --> ',activity_label)\n",
    "                    \n",
    "                    globals()['{}'.format(activity_label)]+=15\n",
    "                    print(globals()['{}'.format(activity_label)],'행동 15초 추가')\n",
    "                    \n",
    "                    #공부시간 계산\n",
    "                    if y_pred[0] in [1,3,5]:\n",
    "                        study_time += 15\n",
    "                        print('study_time',study_time)\n",
    "                    else:\n",
    "                        notstudy_time += 15\n",
    "                        alarm_notstudy += 15\n",
    "                        print('notstudy_time',notstudy_time)\n",
    "                        \n",
    "                    if alarm_notstudy >= 300:\n",
    "                        sound = SoundLoader.load('kv/alarm.wav')\n",
    "                        sound.play()\n",
    "                        alarm_notstudy = 0\n",
    "                    \n",
    "                \n",
    "                analysis_num = 0\n",
    "                print('분석종료 analysis_num',analysis_num)\n",
    "                \n",
    "\n",
    "            if 100<=sample_num<=190:\n",
    "                record = True\n",
    "\n",
    "            if record == True:\n",
    "                out.write(frame)\n",
    "\n",
    "            if sample_num > 191:\n",
    "                #record = False\n",
    "                # print(sample_num)\n",
    "                captured_num += 1\n",
    "                analysis_num += 1\n",
    "                # print('captured_num',captured_num)\n",
    "                # print('analysis_num',analysis_num)\n",
    "                \n",
    "                record = False\n",
    "                sample_num = 0\n",
    "                out = cv2.VideoWriter('data/dataset/video_{:04d}.mp4'.format(captured_num), fourcc, fps, (w, h))\n",
    "                \n",
    "            if cv2.waitKey(delay) == 27: # esc를 누르면 강제 종료\n",
    "                a = datetime.today()\n",
    "                format = '%Y-%m-%d'\n",
    "                str_datetime = datetime.strftime(a,format)\n",
    "                print('str_datetime',str_datetime)\n",
    "\n",
    "                print('최종집중시간',study_time)\n",
    "                print('최종비집중시간',notstudy_time)\n",
    "                \n",
    "                with open('time.csv', 'r', encoding='UTF-8') as f:\n",
    "                    reader = csv.reader(f)\n",
    "                    station_info = list(reader)\n",
    "                    for i in range(1,len(station_info)):\n",
    "                        if station_info[i][0] == str_datetime :\n",
    "                            station_info[i][1]=int(station_info[i][1])+int(study_time)\n",
    "\n",
    "                with open('time.csv', 'w', encoding='UTF-8', newline='') as f:\n",
    "                    wr = csv.writer(f)\n",
    "                    for i in range(len(station_info)):\n",
    "                        wr.writerow(station_info[i])\n",
    "                \n",
    "                f.close()\n",
    "                break\n",
    "                \n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return study_time, notstudy_time, writing, reading, using_computer, leaving_seat, sleeping, using_smartphone\n",
    "    def get_date(self):\n",
    "        a = datetime.today()\n",
    "        format = '%Y-%m-%d'\n",
    "        str_datetime = datetime.strftime(a,format)\n",
    "        return str_datetime\n",
    "    \n",
    "    def get_study_result(self):\n",
    "        global study_time\n",
    "        hours = study_time // 3600\n",
    "        study_time = study_time - hours*3600\n",
    "        mu = study_time // 60\n",
    "        ss = study_time - mu*60\n",
    "        study_result = '{}h {}m {}s'.format(hours,mu,ss)\n",
    "        return study_result\n",
    "    \n",
    "    def get_not_study_result(self):\n",
    "        global notstudy_time\n",
    "        hours = notstudy_time // 3600\n",
    "        notstudy_time = notstudy_time - hours*3600\n",
    "        mu = notstudy_time // 60\n",
    "        ss = notstudy_time - mu*60\n",
    "        notstudy_result = '{}h {}m {}s'.format(hours,mu,ss)\n",
    "        return notstudy_result\n",
    "    \n",
    "    def get_daily_study_result(self):\n",
    "        a = datetime.today()\n",
    "        format = '%Y-%m-%d'\n",
    "        str_datetime = datetime.strftime(a,format)\n",
    "        print('str_datetime',str_datetime)\n",
    "        \n",
    "        with open('time.csv', 'r', encoding='UTF-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            station_info = list(reader)  \n",
    "            for i in range(1,len(station_info)):\n",
    "                if station_info[i][0] == str_datetime :\n",
    "                    daily_time = station_info[i][1]\n",
    "        print('daily_time',daily_time)\n",
    "        hours = int(daily_time) // 3600\n",
    "        daily_time = int(daily_time) - hours*3600\n",
    "        mu = int(daily_time) // 60\n",
    "        ss = int(daily_time) - mu*60\n",
    "        daily_time = '{}h {}m {}s'.format(hours,mu,ss)\n",
    "\n",
    "        return daily_time\n",
    "    \n",
    "    def get_weekly_study_result(self):\n",
    "        week = datetime.now().isocalendar()[1]\n",
    "        print('week',week)\n",
    "        week_time = 0\n",
    "\n",
    "        with open('time.csv', 'r', encoding='UTF-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            station_info = list(reader)\n",
    "            for i in range(1,len(station_info)):\n",
    "                wyear = int(station_info[1][0][0:4])\n",
    "                wmonth = int(station_info[1][0][6])\n",
    "                wday = int(station_info[1][0][8:10])\n",
    "                date = datetime(wyear,wmonth,wday)\n",
    "                iso_calendar = date.isocalendar()\n",
    "                print('iso_calendar[1]',iso_calendar[1])\n",
    "                if int(week) == 22:\n",
    "                    week = 21\n",
    "                print('week',week,type(week))\n",
    "                if int(iso_calendar[1]) == int(week) :\n",
    "                    try : \n",
    "                        week_time += int(station_info[i][1])\n",
    "                        print('week_time',week_time)\n",
    "                    except :\n",
    "                        pass\n",
    "        \n",
    "        print('week_time',week_time)\n",
    "        hours = int(week_time) // 3600\n",
    "        week_time = int(week_time) - hours*3600\n",
    "        mu = int(week_time) // 60\n",
    "        ss = int(week_time) - mu*60\n",
    "        week_time = '{}h {}m {}s'.format(hours,mu,ss)\n",
    "        return week_time\n",
    "    \n",
    "    def get_monthly_study_result(self):\n",
    "        month = int(datetime.today().month)\n",
    "        month_time=0\n",
    "        with open('time.csv', 'r', encoding='UTF-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            station_info = list(reader)\n",
    "            for i in range(1,len(station_info)):\n",
    "                if int(station_info[i][0][6]) == month :\n",
    "                    try :\n",
    "                        month_time += int(station_info[i][1])\n",
    "                    except : \n",
    "                        pass\n",
    "        print('month_time',month_time)\n",
    "        hours = int(month_time) // 3600\n",
    "        month_time = int(month_time) - hours*3600\n",
    "        mu = int(month_time) // 60\n",
    "        ss = int(month_time) - mu*60\n",
    "        month_time = '{}h {}m {}s'.format(hours,mu,ss)\n",
    "        return month_time\n",
    "    \n",
    "    def update_donut_graph(self):\n",
    "        global writing, reading, using_computer, leaving_seat, sleeping, using_smartphone\n",
    "        plt.clf()  # clear the plot\n",
    "        #graph_1 = MDApp.get_running_app().root.get_screen('registration_screen')\n",
    "        #graph_1.ids.expense_graph.clear_widgets()\n",
    "        # create data\n",
    "        labels = ['writing', 'reading', 'using_computer', 'leaving_seat','sleeping','using_smartphone']\n",
    "        total = writing+reading+using_computer+leaving_seat+sleeping+using_smartphone\n",
    "        data_values = [(writing/total)*100,(reading/total)*100,(using_computer/total)*100,(leaving_seat/total)*100,(sleeping/total)*100,(using_smartphone/total)*100]\n",
    "        colors = ['#ff9999', '#ffc000', '#8fd9b6','silver', 'whitesmoke', 'blue']\n",
    "        # Create a white circle for the center of the plot\n",
    "        my_circle = plt.Circle((0, 0), 0.65, color='white')\n",
    "        # Create graph, add and place percentage labels\n",
    "        # Add spaces to separate elements from the donut\n",
    "        explode = (0.05, 0.05, 0.05, 0.05, 0.05, 0.05)\n",
    "        plt.pie(data_values, autopct=\"%.1f%%\", startangle=0, pctdistance=0.80, labeldistance=1.2, explode=explode, colors=colors)\n",
    "        p = plt.gcf()\n",
    "        p.gca().add_artist(my_circle)\n",
    "        # Create and place legend of the graph\n",
    "        plt.legend(labels=labels, loc=\"center\", fontsize='xx-small')\n",
    "        # Add graph to Kivy App\n",
    "        # plt.show()\n",
    "        # THE DESIRED RESULT IS TO ADD THE GRAPH TO THE APP WITH THE LINE OF CODE BELOW, INSTEAD OF THE plt.show() line\n",
    "        #graph = self.ids.graph\n",
    "        #graph.add_widget(FigureCanvasKivyAgg(figure=plt.gcf()))\n",
    "        \n",
    "        \n",
    "        plt.savefig('graph.png',dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    def build(self):\n",
    "        self.bind(on_start=self.post_build_init)\n",
    "        self.sm.add_widget(Factory.LoginScreen())\n",
    "        # self.sm.add_widget(HomeScreen(name=\"home_screen\"))\n",
    "        # self.sm.current = \"login_screen\"\n",
    "        return self.sm\n",
    "\n",
    "    def post_build_init(self, ev):\n",
    "        win = self._app_window\n",
    "        win.bind(on_keyboard=self._key_handler)\n",
    "\n",
    "    def _key_handler(self, *args):\n",
    "        key = args[1]\n",
    "        # 1000 is \"back\" on Android\n",
    "        # 27 is \"escape\" on computers\n",
    "        if key in (1000, 27):\n",
    "            try:\n",
    "                self.sm.current_screen.dispatch(\"on_back_pressed\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            return True\n",
    "        elif key == 1001:\n",
    "            try:\n",
    "                self.sm.current_screen.dispatch(\"on_menu_pressed\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            return True\n",
    "        \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    Emp().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
